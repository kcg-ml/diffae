{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.transforms import functional as VF\n",
    "\n",
    "from templates import ffhq256_autoenc, LitModel"
   ],
   "id": "da96b18b5c1ba66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "device = 'cuda'\n",
    "\n",
    "conf = ffhq256_autoenc()\n",
    "\n",
    "model = LitModel(conf)\n"
   ],
   "id": "4d66f421dbc620fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load Image\n",
    "\n",
    "img = Image.open('example.jpg').resize((256, 256)).convert('RGB')"
   ],
   "id": "66599ce24f785418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Encode\n",
    "\n",
    "xsem = model.encode(x)"
   ],
   "id": "89b2012572f7b91"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
